{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lekB0j-YtH3y",
        "outputId": "67579100-c3b9-4f01-a70c-a4db0c650fe0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import math\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch import Tensor\n",
        "from torch.autograd import grad\n",
        "\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "\n",
        "if 'higher' not in sys.modules:\n",
        "  !pip install higher\n",
        "import higher as higher\n",
        "\n",
        "print(sys.version)\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10Wp24Y017h5"
      },
      "outputs": [],
      "source": [
        "# Set random seeds\n",
        "random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "\n",
        "# Set important parameters\n",
        "learning_rate = 1e-2\n",
        "inner_loop_iterations = 32\n",
        "outer_loop_iterations = 5\n",
        "num_classes = 10\n",
        "\n",
        "noise_size = 64     # size of noise or curriculum vector\n",
        "img_size = 28    # width / height of generated image\n",
        "\n",
        "inner_loop_batch_size = 128\n",
        "outer_loop_batch_size = 128\n",
        "\n",
        "mnist_mean = 0.1307         # for normalizing mnist images\n",
        "mnist_std = 0.3081          # for normalizing mnist images\n",
        "\n",
        "imgs_per_row = num_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pc17E5a6tWWc",
        "outputId": "c76ead8b-b23c-4b08-f34c-35e28638b3c3"
      },
      "outputs": [],
      "source": [
        "# Initialize MNIST transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Lambda(lambda x: np.array(x)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((mnist_mean,), (mnist_std,)),\n",
        "])\n",
        "\n",
        "# Create data splits\n",
        "train = datasets.MNIST('./data', train=True, transform=transform, download=True)\n",
        "train, val = torch.utils.data.random_split(train, [50000, 10000])\n",
        "test = datasets.MNIST('./data', train=False, transform=transform, download=True)\n",
        "print('Created train, val, and test datasets.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6oWjCknt0-9"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train, batch_size=outer_loop_batch_size, shuffle=True, drop_last=True, num_workers=1, pin_memory=True,\n",
        ")\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val, batch_size=outer_loop_batch_size, shuffle=True, drop_last=True, num_workers=1, pin_memory=True,\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test, batch_size=outer_loop_batch_size, shuffle=True, drop_last=True, num_workers=1, pin_memory=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKsF5G1V68sC"
      },
      "outputs": [],
      "source": [
        "class Teacher(nn.Module):\n",
        "    '''\n",
        "    Implements a Teacher module.\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        conv1_filters = 64\n",
        "        fc1_size = 1024\n",
        "\n",
        "        self.fc2_filters = 128\n",
        "        self.fc2_width = img_size\n",
        "        fc2_size = self.fc2_filters * self.fc2_width * self.fc2_width\n",
        "\n",
        "        self.fc1 = nn.Linear(noise_size + num_classes, fc1_size)\n",
        "        nn.init.kaiming_normal_(self.fc1.weight, 0.1)\n",
        "        self.bn_fc1 = nn.BatchNorm1d(fc1_size, momentum=0.1)\n",
        "\n",
        "        self.fc2 = nn.Linear(fc1_size, fc2_size)\n",
        "        nn.init.kaiming_normal_(self.fc2.weight, 0.1)\n",
        "        self.bn_fc2 = nn.BatchNorm2d(self.fc2_filters, momentum=0.1)\n",
        "\n",
        "        self.conv1 = nn.Conv2d(self.fc2_filters, conv1_filters, 3, 1, padding=3 // 2)\n",
        "        self.bn_conv1 = nn.BatchNorm2d(conv1_filters, momentum=0.1)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(conv1_filters, 1, 3, 1, padding=3 // 2)\n",
        "        self.bn_conv2 = nn.BatchNorm2d(1, momentum=0.1)\n",
        "\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "        self.learner_optim_params = nn.Parameter(torch.tensor([0.02, 0.5]), True)\n",
        "\n",
        "    def forward(self, x, target):\n",
        "        '''\n",
        "        Synthesizes a batch of training examples for the learner.\n",
        "        Args:\n",
        "            x (torch.tensor): shape (b, 64)\n",
        "            target (torch.tensor): shape (b, 10)\n",
        "        '''\n",
        "        # Fully connected block 1\n",
        "        x = torch.cat([x, target], dim=1)   # shape (b, 64+10)\n",
        "        x = self.fc1(x)                     # shape (b, 1024)\n",
        "        x = F.leaky_relu(x, 0.1)\n",
        "        x = self.bn_fc1(x)\n",
        "\n",
        "        # Fully connected block 2\n",
        "        x = self.fc2(x)                     # shape (b, 128*28*28)\n",
        "        x = F.leaky_relu(x, 0.1)\n",
        "        x = x.view(                         # shape (b, 128, 28, 28)\n",
        "            -1, self.fc2_filters, self.fc2_width, self.fc2_width\n",
        "        )\n",
        "        x = self.bn_fc2(x)\n",
        "\n",
        "        # Convolutional block 1\n",
        "        x = self.conv1(x)                   # shape (b, 64, 28, 28)\n",
        "        x = self.bn_conv1(x)\n",
        "        x = F.leaky_relu(x, 0.1)\n",
        "\n",
        "        # Convolutional block 2\n",
        "        x = self.conv2(x)                   # shape (b, 1, 28,  28)\n",
        "        x = self.bn_conv2(x)\n",
        "\n",
        "        x = (self.tanh(x) + 1 - 2 * mnist_mean) / (2 * mnist_std)\n",
        "        return x, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZqp0lAz7CmR"
      },
      "outputs": [],
      "source": [
        "class Learner(nn.Module):\n",
        "    '''\n",
        "    Implements a Learner module.\n",
        "    '''\n",
        "    def __init__(self, num_conv1=None, num_conv2=None):\n",
        "        super().__init__()\n",
        "\n",
        "        # Randomly select and evaluate convolutional depth\n",
        "        # for evaluation/comparison in neural architecture search\n",
        "        if num_conv1 is None:\n",
        "            conv1_filters = np.random.randint(32, 64)\n",
        "        else:\n",
        "            conv1_filters = num_conv1\n",
        "        if num_conv2 is None:\n",
        "            conv2_filters = np.random.randint(64, 128)\n",
        "        else:\n",
        "            conv2_filters = num_conv2\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, conv1_filters, 3, 1)\n",
        "        self.bn1 = nn.BatchNorm2d(conv1_filters, momentum=0.1)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(conv1_filters, conv2_filters, 3, 1)\n",
        "        self.bn2 = nn.BatchNorm2d(conv2_filters, momentum=0.1)\n",
        "\n",
        "        c1_size = (img_size - 3 + 1) // 2\n",
        "        c2_size = (c1_size - 3 + 1) // 2\n",
        "\n",
        "        self.fc = nn.Linear(conv2_filters * c2_size * c2_size, num_classes)\n",
        "        self.bn3 = nn.BatchNorm1d(num_classes, momentum=0.1)\n",
        "\n",
        "        self.activation = nn.LeakyReLU(0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.bn1(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.bn2(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        x = self.bn3(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KLgaZ8Q7EUj"
      },
      "outputs": [],
      "source": [
        "def generate_img(img_tensor):\n",
        "    '''\n",
        "    Function that renders an MNIST image.\n",
        "    '''\n",
        "    return torchvision.transforms.ToPILImage()(1 - ((img_tensor * mnist_std) + mnist_mean))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSL8cTcH55bK"
      },
      "outputs": [],
      "source": [
        "teacher = Teacher()\n",
        "params_to_train = list(teacher.parameters())\n",
        "\n",
        "# If we want to use a curriculum, we initialize the learnable parameters here\n",
        "use_curriculum = True\n",
        "if use_curriculum:\n",
        "    curriculum = nn.Parameter(torch.randn(inner_loop_iterations, inner_loop_batch_size, noise_size), requires_grad=True)\n",
        "    params_to_train += [curriculum]\n",
        "\n",
        "optimizer_teacher = optim.Adam(params_to_train, lr=learning_rate)\n",
        "\n",
        "# For each inner loop iterations, we use the same sequence of labels.\n",
        "# This allows the curriculum vectors to train to stable labels\n",
        "label = torch.tensor([x % num_classes for x in range(inner_loop_batch_size)])\n",
        "\n",
        "# For the inner loop loss, we use cross entropy\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Here we initialize iterators on the train and val datasets\n",
        "train_iterator = iter(train_loader)\n",
        "val_iterator = iter(val_loader)\n",
        "test_iterator = iter(test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "ULasVbFGqCUd",
        "outputId": "9b7ecf41-a245-41d1-eb52-fdd304e7e663"
      },
      "outputs": [],
      "source": [
        "for it, real_data in enumerate(train_loader):\n",
        "\n",
        "    teacher.train()\n",
        "    optimizer_teacher.zero_grad()\n",
        "\n",
        "    # We also optimize the learner learning rate and momentum with the\n",
        "    # outer loop updates\n",
        "    learner_lr = teacher.learner_optim_params[0]\n",
        "    learner_momentum = teacher.learner_optim_params[1]\n",
        "\n",
        "    # Here we sample a learner with random number of conv filters\n",
        "    learner = Learner()\n",
        "    inner_optim = optim.SGD(learner.parameters(), lr=learner_lr.item(), momentum=learner_momentum.item())\n",
        "    learner.train()\n",
        "\n",
        "    inner_losses = []\n",
        "    with higher.innerloop_ctx(learner, inner_optim, override={'lr': [learner_lr], 'momentum': [learner_momentum]}) as (flearner, diffopt):\n",
        "        for step in range(inner_loop_iterations):\n",
        "\n",
        "            # Data generation\n",
        "            if use_curriculum:\n",
        "                z_vec = curriculum[step]\n",
        "            else:\n",
        "                z_vec = torch.randn(inner_loop_batch_size, noise_size)\n",
        "\n",
        "            one_hot = F.one_hot(label, num_classes)\n",
        "\n",
        "            # Pass input to teacher to generate synthetic images\n",
        "            teacher_output, teacher_target = teacher(z_vec, one_hot)\n",
        "\n",
        "            # ====== Show intermediate generated images ======\n",
        "            if step == 0:\n",
        "                print('------------------ Outer loop iteration', it + 1, '------------------')\n",
        "                print('Examples 0 - 9 from beginning of inner loop:')\n",
        "                background = Image.new('L', (img_size * imgs_per_row + imgs_per_row + 1, img_size + 2))\n",
        "                for i in range(imgs_per_row): # indexes column\n",
        "                    background.paste(generate_img(teacher_output[i]), (i * 28 + i + 1, 1))\n",
        "                display(background)\n",
        "\n",
        "            if step == (inner_loop_iterations - 1):\n",
        "                print('Examples 0 - 9 from end of inner loop:')\n",
        "                background = Image.new('L', (img_size * imgs_per_row + imgs_per_row + 1, img_size + 2))\n",
        "                for i in range(imgs_per_row): # indexes column\n",
        "                    background.paste(generate_img(teacher_output[i]), (i * 28 + i + 1, 1))\n",
        "                display(background)\n",
        "\n",
        "            # Pass teacher output to the learner\n",
        "            learner_output = flearner(teacher_output)\n",
        "            loss = loss_fn(learner_output, label)\n",
        "            diffopt.step(loss)\n",
        "\n",
        "            inner_losses.append(loss.item())\n",
        "\n",
        "        correct = 0\n",
        "        data, target = real_data\n",
        "        output = flearner(data)\n",
        "        loss = loss_fn(output, target)\n",
        "        pred = output.argmax(dim=1, keepdim=True)\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "        accuracy_train = correct / target.shape[0]\n",
        "\n",
        "        print(\"Inner loop losses:\", inner_losses)\n",
        "        print(\"Train accuracy:\", accuracy_train)\n",
        "\n",
        "        # Compute accuracy on validation set\n",
        "        data, target = next(val_iterator)\n",
        "        print\n",
        "        output = flearner(data)\n",
        "        pred = output.argmax(dim=1, keepdim=True)\n",
        "        correct = pred.eq(target.view_as(pred)).sum().item()\n",
        "        accuracy = correct / outer_loop_batch_size\n",
        "        print(\"Val accuracy:\", accuracy)\n",
        "\n",
        "        if (it == outer_loop_iterations - 1):\n",
        "            # Compute accuracy on test set\n",
        "            correct = 0\n",
        "            for i, (data, target) in enumerate(test_loader):\n",
        "                output = flearner(data)\n",
        "                pred = output.argmax(dim=1, keepdim=True)\n",
        "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            accuracy = correct / (outer_loop_batch_size * len(test_loader))\n",
        "            print(\"----------------------------------\")\n",
        "            print(\"Done training...\")\n",
        "            print(\"Final test accuracy:\", accuracy)\n",
        "\n",
        "            # Final inner loop training curve\n",
        "            plt.plot(np.arange(len(inner_losses)), inner_losses)\n",
        "            plt.xlabel(\"Inner loop iteration\")\n",
        "            plt.ylabel(\"Cross entropy loss\")\n",
        "            plt.show()\n",
        "\n",
        "            break\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "    optimizer_teacher.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hQn3a53uQVc",
        "outputId": "32cb8abb-1045-497d-e855-692135223928"
      },
      "outputs": [],
      "source": [
        "num_architectures = 10\n",
        "\n",
        "best_accuracy = 0\n",
        "\n",
        "for i in range(num_architectures):\n",
        "\n",
        "    # Randomly sample architecture\n",
        "    conv1_filters = np.random.randint(1, 64)\n",
        "    conv2_filters = np.random.randint(1, 128)\n",
        "\n",
        "    learner = Learner(conv1_filters, conv2_filters)\n",
        "    inner_optim = optim.SGD(learner.parameters(), lr=learner_lr.item(), momentum=learner_momentum.item())\n",
        "    learner.train()\n",
        "\n",
        "    # For some reason if we don't use higher here, accuracy drops significantly\n",
        "    with higher.innerloop_ctx(learner, inner_optim, override={'lr': [learner_lr], 'momentum': [learner_momentum]}) as (flearner, diffopt):\n",
        "        for step in range(inner_loop_iterations):\n",
        "\n",
        "            # Data generation\n",
        "            if use_curriculum:\n",
        "                z_vec = curriculum[step]\n",
        "            else:\n",
        "                z_vec = torch.randn(inner_loop_batch_size, noise_size)\n",
        "\n",
        "            one_hot = F.one_hot(label, num_classes)\n",
        "\n",
        "            # Pass input to teacher to generate synthetic images\n",
        "            teacher_output, teacher_target = teacher(z_vec, one_hot)\n",
        "\n",
        "            # Pass teacher output to the learner\n",
        "            learner_output = flearner(teacher_output)\n",
        "            loss = loss_fn(learner_output, label)\n",
        "            diffopt.step(loss)\n",
        "\n",
        "        # Compute accuracy on validation set\n",
        "        correct = 0\n",
        "        for val_idx, (data, target) in enumerate(val_loader, 0):\n",
        "            #if (val_idx == val_iterations): break\n",
        "            output = flearner(data)\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "        accuracy = correct / (outer_loop_batch_size * len(val_loader))\n",
        "\n",
        "        if (accuracy > best_accuracy):\n",
        "            best_accuracy = accuracy\n",
        "            filter_counts = (conv1_filters, conv2_filters)\n",
        "\n",
        "        print(\"------------------------- Architecture\", i + 1,\" -------------------------\")\n",
        "        print(\"Num conv1 filters:\", conv1_filters, \", Num conv2 filters:\", conv2_filters, \", Val accuracy:\", accuracy)\n",
        "\n",
        "\n",
        "        if (i == num_architectures - 1):\n",
        "            correct = 0\n",
        "            for test_idx, (data, target) in enumerate(test_loader, 0):\n",
        "                #if (test_idx == test_iterations): break\n",
        "                output = flearner(data)\n",
        "                pred = output.argmax(dim=1, keepdim=True)\n",
        "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            accuracy = correct / (outer_loop_batch_size * len(test_loader))\n",
        "            print(\"------------------------- Best architecture -------------------------\")\n",
        "            print(\"Num conv1 filters:\", filter_counts[0], \", Num conv2 filters:\", filter_counts[1], \", Test accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "tcNX36MTglMe",
        "outputId": "2edfd256-a370-4df5-a74c-5db4fdf90213"
      },
      "outputs": [],
      "source": [
        "imgs_per_row = num_classes\n",
        "rows = inner_loop_iterations // 2 * img_size + inner_loop_iterations // 2 + 1\n",
        "cols = imgs_per_row * img_size + imgs_per_row + 1\n",
        "background = Image.new('L', (cols, rows))\n",
        "\n",
        "for step in range(0, inner_loop_iterations, 2): # indexes row\n",
        "    if use_curriculum:\n",
        "        z_vec = curriculum[step]\n",
        "    else:\n",
        "        z_vec = torch.randn(inner_loop_batch_size, noise_size)\n",
        "\n",
        "    one_hot = F.one_hot(label, num_classes)\n",
        "\n",
        "    teacher_output, teacher_target = teacher(z_vec, one_hot)\n",
        "\n",
        "    for i in range(imgs_per_row): # indexes column\n",
        "        background.paste(generate_img(teacher_output[i]), (i * img_size + i + 1, (step // 2) * img_size + (step // 2) + 1))\n",
        "\n",
        "display(background)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "name": "C3W1: Generative Teaching Networks (Optional).ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
